{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "662a7088",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import time\n",
    "import pandas as pd\n",
    "\n",
    "# Parameters to run the experiment\n",
    "FUNCTIONS = ['sphere', 'rosenbrock', 'ackley', 'schwefel', 'rastrigin']\n",
    "N_RUNS = 30           # Numbers of independent runs per function\n",
    "MAX_ITERATIONS = 500  # Maximum number of iterations per run\n",
    "DIMENSIONS = 2        # Problem dimensionality\n",
    "TOLERANCE = 1e-3      # Threshold to consider the test a \"Success\"\n",
    "MAX_FEVALS = 50000    # Maximum number of function evaluations\n",
    "KNOWN_OPTIMUM = 0.0   # Known optimum value for the test functions\n",
    "\n",
    "# Parameters to run the optimization algorithm\n",
    "NUM_PARTICLES = 200   # Number of particles\n",
    "ALPHA_START = 0.01    # Initial exploration parameter\n",
    "ALPHA_END = 50.0      # Final exploration parameter\n",
    "LAMBDA = 1.0          # Drift\n",
    "SIGMA = 0.5           # Diffusion\n",
    "DELTA_T = 0.1         # Time step\n",
    "\n",
    "results = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "7f8562d7",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_bounds(func_name):\n",
    "    if func_name == 'schwefel':\n",
    "        return -500, 500\n",
    "    elif func_name == 'rastrigin':\n",
    "        return -5.12, 5.12\n",
    "    else:\n",
    "        return -10, 10\n",
    "\n",
    "def objective_function(x, function_name):\n",
    "    if function_name == 'sphere':\n",
    "        return np.sum(x**2)\n",
    "    elif function_name == 'rosenbrock':\n",
    "        return sum(100.0 * (x[1:] - x[:-1]**2.0)**2.0 + (1 - x[:-1])**2.0)\n",
    "    elif function_name == 'ackley':\n",
    "        first_sum = np.sum(x**2)\n",
    "        second_sum = np.sum(np.cos(2 * np.pi * x))\n",
    "        n = len(x)\n",
    "        return -20 * np.exp(-0.2 * np.sqrt(first_sum / n)) - np.exp(second_sum / n) + 20 + np.e\n",
    "    elif function_name == 'schwefel':\n",
    "        return 418.9829 * len(x) - np.sum(x * np.sin(np.sqrt(np.abs(x))))\n",
    "    elif function_name == 'rastrigin':\n",
    "        return 10 * len(x) + np.sum(x**2 - 10 * np.cos(2 * np.pi * x))\n",
    "    else:\n",
    "        raise ValueError(\"Unknown function name\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "36e92aab",
   "metadata": {},
   "outputs": [],
   "source": [
    "def cbo_optimization(func_name, run_id=1, dims=DIMENSIONS, plotting=False):\n",
    "    # Initialization\n",
    "    lower_bound, upper_bound = get_bounds(func_name)\n",
    "    particles = np.random.uniform(lower_bound, upper_bound, (NUM_PARTICLES, dims))\n",
    "    global_best_cost = float('inf')\n",
    "    global_best_position = particles[0].copy()\n",
    "\n",
    "    epsilon = 1e-3 # Convergence threshold\n",
    "    start_time = time.process_time() # METRICS: Start CPU time measurement\n",
    "    n_fevals = 0\n",
    "    n_fevals_to_success = None\n",
    "    success = False\n",
    "    initial_particles = particles.copy() if plotting else None\n",
    "\n",
    "    for iteration in range(MAX_ITERATIONS):\n",
    "    \n",
    "        # Cost evaluation and weights computation\n",
    "        costs = np.array([objective_function(p, func_name) for p in particles])\n",
    "        n_fevals += NUM_PARTICLES # METRICS: Update number of function evaluations\n",
    "\n",
    "        # Update global best\n",
    "        current_best_index = np.argmin(costs)\n",
    "        if costs[current_best_index] < global_best_cost: \n",
    "            global_best_cost = costs[current_best_index]\n",
    "            global_best_position = particles[current_best_index].copy() \n",
    "\n",
    "        # METRICS: Check for success\n",
    "        if not success and abs(global_best_cost - KNOWN_OPTIMUM) < TOLERANCE:\n",
    "            success = True\n",
    "            n_fevals_to_success = n_fevals\n",
    "        \n",
    "        # Update alpha for exploration-exploitation trade-off\n",
    "        progress = iteration / MAX_ITERATIONS\n",
    "        alpha = ALPHA_START + (ALPHA_END - ALPHA_START) * (progress ** 2)\n",
    "\n",
    "        # Update weights based on costs\n",
    "        v_min = np.min(costs)\n",
    "        v_max = np.max(costs)\n",
    "        denom = v_max - v_min if v_max - v_min > 1e-10 else 1.0\n",
    "        norm_costs = (costs - v_min) / denom\n",
    "        weights = np.exp(-alpha * norm_costs)\n",
    "\n",
    "        # Normalize weights\n",
    "        sum_weights = np.sum(weights)\n",
    "        if sum_weights > 0:\n",
    "            weights /= sum_weights\n",
    "        else:\n",
    "            # Case all weights are zero (can happen with large alpha)\n",
    "            weights = np.ones(NUM_PARTICLES) / NUM_PARTICLES\n",
    "\n",
    "        # Calculate consensus point\n",
    "        consensus_point = np.sum(weights[:, np.newaxis] * particles, axis=0)\n",
    "\n",
    "        diffusion_vector = particles - consensus_point # Diffusion vector for each particle\n",
    "\n",
    "        drift = -LAMBDA * diffusion_vector * DELTA_T # Drift towards consensus point\n",
    "\n",
    "        dist_scalar = np.linalg.norm(diffusion_vector, axis=1, keepdims=True) # Distance from consensus point for each particle\n",
    "\n",
    "        zi = np.random.randn(NUM_PARTICLES, dims) # Standard normal random variables\n",
    "        diffusion = SIGMA * dist_scalar * np.sqrt(DELTA_T) * zi # Diffusion component\n",
    "\n",
    "        particles += drift + diffusion # Update particle positions\n",
    "        particles = np.clip(particles, lower_bound, upper_bound) # Keep particles within bounds\n",
    "\n",
    "        if plotting:\n",
    "            weighted_swarm_radius = np.sum(weights * dist_scalar.flatten())\n",
    "        \n",
    "            if weighted_swarm_radius < epsilon and iteration > 20:\n",
    "                print(f\"Converged after {iteration} iterations.\")\n",
    "                print(f\"Weighted swarm radius: {weighted_swarm_radius:.6f} < epsilon ({epsilon})\")\n",
    "                break\n",
    "\n",
    "    total_time = time.process_time() - start_time # METRICS: Total CPU time\n",
    "    final_error = abs(global_best_cost - KNOWN_OPTIMUM) # METRICS: Final error\n",
    "\n",
    "    return {\n",
    "        \"Function\": func_name,\n",
    "        \"Run_ID\": run_id,\n",
    "        \"Success\": success,\n",
    "        \"Fevals_to_Success\": n_fevals_to_success,\n",
    "        \"Final_Error\": final_error,\n",
    "        \"CPU_Time\": total_time,\n",
    "        \"Global_Best_Cost\": global_best_cost,\n",
    "        \"Global_Best_Pos\": global_best_position,\n",
    "        \"Final_Particles\": particles,\n",
    "        \"Initial_Particles\": initial_particles\n",
    "    }\n",
    "\n",
    "def plot_cbo_state(initial_data, final_data, best_pos, best_cost, func_name, title):\n",
    "    \"\"\"\n",
    "    Plots the initial and final state of the particles on a 2D contour map.\n",
    "    \"\"\"\n",
    "    lower_bound, upper_bound = get_bounds(func_name)\n",
    "    range_width = upper_bound - lower_bound\n",
    "    density = 10 # Points per unit range\n",
    "    min_points = 100\n",
    "    max_points = 400 \n",
    "    num_points = int(min(max(min_points, range_width * density), max_points))\n",
    "    \n",
    "    # Create grid for contour\n",
    "    x = np.linspace(lower_bound, upper_bound, num_points)\n",
    "    y = np.linspace(lower_bound, upper_bound, num_points)\n",
    "    X, Y = np.meshgrid(x, y)\n",
    "\n",
    "    Z = np.array([[objective_function(np.array([i, j, 0]), func_name) for i in x] for j in y])\n",
    "\n",
    "    def get_contour(ax, particle_data, title, show_best=False):\n",
    "        # Background contour plot of the objective function\n",
    "        contour = ax.contourf(X, Y, Z, levels=50, cmap='viridis')\n",
    "        \n",
    "        # Draw all particles\n",
    "        ax.scatter(particle_data[:, 0], particle_data[:, 1], c='white', edgecolors='black', s=30, alpha=0.7, label='Particles')\n",
    "        \n",
    "        # If requested, highlight the Global Best (only in the final plot)\n",
    "        if show_best:\n",
    "            ax.scatter(best_pos[0], best_pos[1], \n",
    "                    c='red', marker='*', s=300, label='Global Best') # s=300 is the size of the star\n",
    "            ax.legend()\n",
    "            \n",
    "        ax.set_title(title)\n",
    "        ax.set_xlabel(\"X\")\n",
    "        ax.set_ylabel(\"Y\")\n",
    "        return contour\n",
    "\n",
    "    fig, (ax1, ax2) = plt.subplots(1, 2, figsize=(16, 7))\n",
    "\n",
    "    get_contour(ax1, initial_data, \"Initial Swarm Distribution\")\n",
    "\n",
    "    contour = get_contour(ax2, final_data, f\"Best Cost: {best_cost:.4f}\", show_best=True)\n",
    "\n",
    "    fig.colorbar(contour, ax=[ax1, ax2], label='Objective Function Cost')\n",
    "\n",
    "    plt.show()\n",
    "\n",
    "def run_experiments():\n",
    "    \"\"\"\n",
    "    Runs the full benchmark suite on all functions (N_RUNS times each).\n",
    "    Saves results to CSV.\n",
    "    \"\"\"\n",
    "    print(f\"Starting Massive Experiment: {N_RUNS} runs per function, {DIMENSIONS} dimensions.\")\n",
    "    all_results = []\n",
    "    \n",
    "    for func in FUNCTIONS:\n",
    "        print(f\"Processing {func}...\")\n",
    "        for run in range(1, N_RUNS + 1):\n",
    "            # Run CBO without storing history\n",
    "            res = cbo_optimization(func, run_id=run, dims=DIMENSIONS, plotting=False)\n",
    "            \n",
    "            # Keep only scalar metrics for DataFrame\n",
    "            metric_data = {k: v for k, v in res.items() if k not in ['Final_Particles', 'Initial_Particles', 'Global_Best_Pos']}\n",
    "            all_results.append(metric_data)\n",
    "            \n",
    "    df = pd.DataFrame(all_results)\n",
    "    filename = \"cbo_results.csv\"\n",
    "    df.to_csv(filename, index=False)\n",
    "    print(f\"\\nExperiment completed. Data saved to {filename}\")\n",
    "    print(\"\\nSummary of Success Rates:\")\n",
    "    print(df.groupby('Function')['Success'].mean())\n",
    "    return df\n",
    "\n",
    "def run_single_execution():\n",
    "    \"\"\"\n",
    "    Interactive mode: Asks user for function name, runs once in 2D, and plots results.\n",
    "    \"\"\"\n",
    "    func_name = input(f\"Enter function to test {FUNCTIONS}: \").lower().strip()\n",
    "    \n",
    "    if func_name not in FUNCTIONS:\n",
    "        print(\"Invalid function name.\")\n",
    "        return\n",
    "\n",
    "    print(f\"Running single execution on {func_name} (2D for visualization)...\")\n",
    "    \n",
    "    # Force 2D for plotting logic\n",
    "    res = cbo_optimization(func_name, run_id=1, dims=2, plotting=True)\n",
    "    \n",
    "    print(f\"Run Completed in {res['CPU_Time']:.4f}s\")\n",
    "    print(f\"Best Cost: {res['Global_Best_Cost']}\")\n",
    "    print(f\"Success: {res['Success']}\")\n",
    "    \n",
    "    plot_cbo_state(\n",
    "        initial_data=res['Initial_Particles'], \n",
    "        final_data=res['Final_Particles'], \n",
    "        best_pos=res['Global_Best_Pos'], \n",
    "        best_cost=res['Global_Best_Cost'], \n",
    "        func_name=func_name, \n",
    "        title=\"CBO Optimization\"\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "77c76224",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting Massive Experiment: 30 runs per function, 10 dimensions.\n",
      "Processing sphere...\n",
      "Processing rosenbrock...\n"
     ]
    }
   ],
   "source": [
    "# Uncomment the first line to run a single execution with plotting or the second line to run the full experiment\n",
    "\n",
    "#run_single_execution()\n",
    "\n",
    "#df_results = run_experiments()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
